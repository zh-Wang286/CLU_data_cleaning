# `CLUProcessor` 技术说明

## 1. 背景

在对话式AI（如聊天机器人）的开发中，训练数据的质量直接决定了模型理解用户意图的准确性。`CLUProcessor` 是本数据清洗工具的核心处理模块，它接收经过初步加载和验证的数据集，并通过一系列计算和分析方法来评估和揭示数据质量问题。

## 2. 目的

`CLUProcessor` 的核心目标是**量化**和**定位**训练数据中的潜在问题。它不依赖于人类的直观感受，而是通过数学和算法模型来回答以下几个关键问题：

-   **意图内部的一致性如何？** 即，同一个意图下的所有句子（utterances）在语义上是否足够相似？是否存在“挂羊头卖狗肉”的异常样本？
-   **意图之间的界限是否清晰？** 即，两个不同的意图之间是否存在大量语义模糊、容易混淆的句子？它们的定义是否可能存在重叠？
-   **哪些意图的样本量过少？** 样本量过少的意图可能导致模型训练不充分，需要补充数据。

## 3. 使用的主要方法

`CLUProcessor` 主要通过以下几个关键步骤完成分析：

### 3.1. 文本向量化 (Text Embedding)

-   **是什么**：这是所有分析的基础。它通过调用 Azure OpenAI 的 `text-embedding-3-small` 模型，将每一句人类语言（如“请帮我重置密码”）转换成一个由数字组成的、高维的数学向量（例如一个包含1536个数字的列表）。
-   **为什么**：计算机无法直接理解文本。将文本转换为向量后，我们就可以在数学上计算它们之间的“距离”或“方向”。在向量空间中，意思相近的句子，其对应的向量在方向上也会更接近。这使得语义分析变为了一个可以精确计算的数学问题。
-   **实现细节**：
    -   **缓存机制**：为了节省成本和时间，计算出的向量会被缓存到本地文件。下次对同样的数据集运行时，会直接从缓存加载，无需重新调用API。
    -   **批量处理**：将多个句子打包成一批，一次性发送给API，以提升网络效率。
    -   **自动重试**：如果网络请求失败，系统会以指数级增加等待时间的方式自动重试，增强了程序的稳定性。

### 3.2. 意图内异常点检测 (Intra-Intent Outlier Detection)

-   **是什么**：此方法逐一检查每个意图，找出该意图内部语义最不合群的句子。
-   **为什么**：一个意图下的所有句子理应围绕一个核心语义。如果某个句子的语义向量与其他所有句子的向量都相距甚远，那么它很可能是一个异常点（比如一个被错误标注的句子，或者一个表达方式非常独特的极端案例）。
-   **实现原理 (k-NN)**：
    1.  针对一个意图（如“查询天气”），取出其下所有句子的向量。
    2.  对每个向量，计算它与其他所有向量的**余弦距离**。余弦距离衡量向量方向的差异，是文本语义分析的常用指标。
    3.  找到离它“最近”的一个邻居（k=1），这个邻居与它的距离就是这个句子的**异常分数**。分数越高，代表它越“孤立”。
    4.  使用统计学方法（如“95百分位”），为该意图内的所有异常分数计算出一个**阈值**。
    5.  所有异常分数超过这个阈值的句子，就被判定为离群点。

### 3.3. 全局聚类审计 (Global Clustering Audit)

-   **是什么**：此方法忽略所有句子原有的意图标签，将整个数据集中的所有句子向量“扔”在一起，让算法根据语义相似性自由地将它们分成若干个“簇”。
-   **为什么**：这是一种“无监督”的审查方式。如果数据质量良好，那么理想情况下，一个算法形成的“簇”应该主要由来自同一个原始意图的句子组成。如果一个簇里高比例地混合了来自“意图A”和“意图B”的句子，这就强烈暗示“意图A”和“意图B”的定义可能过于相似，存在边界不清的问题。
-   **实现原理 (HDBSCAN)**：
    -   HDBSCAN 是一种强大的密度聚类算法。它能自动识别出数据中不同密度（即句子向量在空间中的疏密程度）的区域，并将其划分为簇。
    -   它的一个重要优点是能够将不属于任何一个簇的“噪声点”识别出来，这有助于我们过滤掉那些语义模糊、无法归类的句子。

### 3.4. 数据增广 (Data Enrichment)

-   **是什么**：对于那些样本量过少的意图，此方法调用大语言模型（LLM）来生成新的、语义一致的候选句子。
-   **为什么**：机器学习模型需要足够多的样本才能学习好一个意图。此功能旨在半自动化地为数据量不足的意图“补充弹药”。
-   **实现原理**：
    1.  找出样本量低于指定阈值（如25条）的意图。
    2.  为每个这类意图，构建一个详细的指令（Prompt），该指令包含意图的定义、已有的话语范例、具体的多样性生成指导以及输出格式要求。
    3.  将这个指令发送给大语言模型，让其“模仿”并“创作”出新的句子。
    4.  方法返回一个包含所有生成结果的字典，供上层调用者（如CLI）进行处理。

## 4. 输出产物及解读

### 4.1. 完整分析 (`run-all` 命令)

运行 `run-all` 命令后，您会在 `outputs/` 目录下看到以下产物：

-   **审计报告 (位于 `outputs/reports/`)**:
    -   这是一个带时间戳的 Markdown (`.md`) 文件，是您最应关注的核心产物。它汇总了所有分析结果：
        -   **数据集概览**：提供了意图和话语的总数，并列出了哪些意图的样本量过少。
        -   **意图内部异常点检测**：分意图列出所有被识别为异常点的话语、它们的异常分数和判断阈值。**您应重点审查此列表中的句子，判断它们是否被错误标注。**
        -   **全局聚类审计**：列出所有被算法发现的“簇”。对于每个簇，报告会显示其大小、其中哪个原始意图的句子占多数（主要意图），以及这个多数意图的占比（纯度）。**您应重点关注那些“纯度”较低的簇，这表明其中混合的意图可能存在定义重叠。**

-   **可视化图表 (位于 `outputs/figures/<运行时间>/`)**:
    -   **意图相似度热力图** (`intent_similarity_heatmap.png`)：一个矩阵图，颜色越亮表示两个意图的语义中心越接近。**可用于快速发现哪些意图对在语义上可能过于相似。**
    -   **全局话语散点图** (`global_scatterplot.png`)：所有话语在二维空间中的分布图。不同颜色代表不同的原始意图。**可用于宏观地观察整个数据集的结构，看不同意图的“领地”是否有明显重叠。**
    -   **意图内话语散点图** (`intent_*.png`)：每个意图一张图。图中标出了正常点（蓝色圆圈）和被判定的异常点（红色叉号），并附上了异常点的文本内容。**这是对审计报告中异常点列表的直观可视化，帮助您理解为何某个点被判定为异常。**

### 4.2. 数据增广 (`enrich` 命令)

运行 `enrich` 命令后，默认会在 `outputs/reports/` 目录下生成一份独立的、带时间戳的 Markdown 报告 (`enrichment_report_*.md`)。

-   **增广建议报告**：这份报告包含了为每个低样本意图生成的所有候选话语。**您应在人工审核这些话语后，再决定是否将它们加入您的原始数据集。** 如果您希望直接在控制台查看结果而不生成文件，可以使用 `--dry-run` 标志。
