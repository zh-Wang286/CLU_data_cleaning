# `CLUProcessor` 技术说明

## 1. 背景

在对话式AI（如聊天机器人）的开发中，训练数据的质量直接决定了模型理解用户意图的准确性。`CLUProcessor` 是本数据清洗工具的核心处理模块，它接收经过初步加载和验证的数据集，并通过一系列计算和分析方法来评估和揭示数据质量问题。

## 2. 目的

`CLUProcessor` 的核心目标是**量化**和**定位**训练数据中的潜在问题。它不依赖于人类的直观感受，而是通过数学和算法模型来回答以下几个关键问题：

-   **意图内部的一致性如何？** 即，同一个意图下的所有句子（utterances）在语义上是否足够相似？是否存在“挂羊头卖狗肉”的异常样本？
-   **意图之间的界限是否清晰？** 即，两个不同的意图之间是否存在大量语义模糊、容易混淆的句子？它们的定义是否可能存在重叠？
-   **哪些意图的样本量过少？** 样本量过少的意图可能导致模型训练不充分，需要补充数据。

## 3. 使用的主要方法

`CLUProcessor` 主要通过以下几个关键步骤完成分析：

### 3.1. 文本向量化 (Text Embedding)

-   **是什么**：这是所有分析的基础。它通过调用 Azure OpenAI 的 `text-embedding-3-large` 模型，将每一句人类语言（如“请帮我重置密码”）转换成一个由数字组成的、高维的数学向量（例如一个包含3072个数字的列表）。
-   **为什么**：计算机无法直接理解文本。将文本转换为向量后，我们就可以在数学上计算它们之间的“距离”或“方向”。在向量空间中，意思相近的句子，其对应的向量在方向上也会更接近。这使得语义分析变为了一个可以精确计算的数学问题。
-   **实现细节**：
    -   **缓存机制**：为了节省成本和时间，计算出的向量会被缓存到本地文件。下次对同样的数据集运行时，会直接从缓存加载，无需重新调用API。
    -   **批量处理**：将多个句子打包成一批，一次性发送给API，以提升网络效率。
    -   **自动重试**：如果网络请求失败，系统会以指数级增加等待时间的方式自动重试，增强了程序的稳定性。

### 3.2. 意图内异常点检测 (Intra-Intent Outlier Detection)

-   **是什么**：此方法逐一检查每个意图，找出该意图内部语义最不合群的句子。
-   **为什么**：一个意图下的所有句子理应围绕一个核心语义。如果某个句子的语义向量与其他所有句子的向量都相距甚远，那么它很可能是一个异常点（比如一个被错误标注的句子，或者一个表达方式非常独特的极端案例）。
-   **实现原理 (k-NN)**：
    1.  针对一个意图（如“查询天气”），取出其下所有句子的向量。
    2.  对每个向量，计算它与其他所有向量的**余弦距离**。余弦距离衡量向量方向的差异，是文本语义分析的常用指标。
    3.  找到离它“最近”的一个邻居（k=1），这个邻居与它的距离就是这个句子的**异常分数**。分数越高，代表它越“孤立”。
    4.  使用统计学方法（如“95百分位”），为该意图内的所有异常分数计算出一个**阈值**。
    5.  所有异常分数超过这个阈值的句子，就被判定为离群点。

### 3.3. 全局聚类审计 (Global Clustering Audit)

-   **是什么**：此方法忽略所有句子原有的意图标签，将整个数据集中的所有句子向量“扔”在一起，让算法根据语义相似性自由地将它们分成若干个“簇”。
-   **为什么**：这是一种“无监督”的审查方式。如果数据质量良好，那么理想情况下，一个算法形成的“簇”应该主要由来自同一个原始意图的句子组成。如果一个簇里高比例地混合了来自“意图A”和“意图B”的句子，这就强烈暗示“意图A”和“意图B”的定义可能过于相似，存在边界不清的问题。
-   **实现原理 (HDBSCAN)**：
    -   HDBSCAN 是一种强大的密度聚类算法。它能自动识别出数据中不同密度（即句子向量在空间中的疏密程度）的区域，并将其划分为簇。
    -   它的一个重要优点是能够将不属于任何一个簇的“噪声点”识别出来，这有助于我们过滤掉那些语义模糊、无法归类的句子。

### 3.4. 意图边界混淆分析 (Boundary Violation Analysis)

-   **是什么**：在完成了前述的宏观聚类审计后，此方法提供了一种更精细、更具统计意义的方式来审查意图边界。它会逐一检查每个话语，并计算它在统计上“看起来”有多么像另一个意图的成员。
-   **为什么**：这个分析的目标是精确地找出那些“身在曹营心在汉”的话语。例如，一个标注为“查询天气”的话语，其语义可能与“查询空气质量”意图的平均语义非常接近。这种方法能将这种混淆用具体的概率值量化出来。
-   **实现原理 (PCA + 马氏距离)**：
    1.  **处理“维度灾难” (PCA)**：直接在高维空间（例如3072维）中计算向量的分布形状是极其不稳定的，特别是当每个意图的样本量远小于维度数时。因此，我们首先使用**主成分分析 (PCA)** 将所有话语向量从高维空间投影到一个保留了主要信息、但维度低得多的新空间。这个新空间的维度根据样本量最少的意图来动态确定，确保后续计算的数值稳定性。
    2.  **计算分布形状 (均值和协方差)**：在降维后的空间里，为每个意图计算其话语分布的中心点（均值向量）和形状（协方差矩阵）。
    3.  **衡量归属可能性 (马氏距离)**：对每个话语，计算它到**其他所有意图**分布中心的**马氏距离**。马氏距离是一种考虑了数据分布形状的距离度量，它能判断一个点是否是某个分布中的“典型”成员。
    4.  **转换为概率 (p-value)**：将马氏距离转换为一个 p-value。这个值可以被通俗地理解为：“假如我们认定这个话语属于目标意图，那么这个认定的合理性有多高”。一个高的 p-value (例如 > 0.05) 强烈暗示这个话语可以被合理地看作是另一个意图的成员。
    5.  **输出报告**：最后，系统会报告所有 p-value 超过阈值的话语，指出它们的原始意图以及最可能与之混淆的目标意图。

### 3.5. 数据增广 (Data Enrichment)

-   **是什么**：对于那些样本量过少的意图，此方法调用大语言模型（LLM）来生成新的、语义一致的候选句子。
-   **为什么**：机器学习模型需要足够多的样本才能学习好一个意图。此功能旨在半自动化地为数据量不足的意图“补充弹药”。
-   **实现原理**：
    1.  找出样本量低于指定阈值（如25条）的意图。
    2.  为每个这类意图，构建一个详细的指令（Prompt），该指令包含意图的定义、已有的话语范例、具体的多样性生成指导以及输出格式要求。
    3.  将这个指令发送给大语言模型，让其“模仿”并“创作”出新的句子。
    4.  方法返回一个包含所有生成结果的字典，供上层调用者（如CLI）进行处理。

## 4. 输出产物及解读

### 4.1. 完整分析 (`run-all` 命令)

运行 `run-all` 命令后，您会在 `outputs/` 目录下看到以下产物：

-   **审计报告 (位于 `outputs/reports/`)**:
    -   这是一个带时间戳的 Markdown (`.md`) 文件，是您最应关注的核心产物。它汇总了所有分析结果：
        -   **数据集概览**：提供了意图和话语的总数，并列出了哪些意图的样本量过少。
        -   **意图内部异常点检测**：分意图列出所有被识别为异常点的话语、它们的异常分数和判断阈值。**您应重点审查此列表中的句子，判断它们是否被错误标注。**
        -   **全局聚类审计**：列出所有被算法发现的“簇”。对于每个簇，报告会显示其大小、其中哪个原始意图的句子占多数（主要意图），以及这个多数意图的占比（纯度）。**您应重点关注那些“纯度”较低的簇，这表明其中混合的意图可能存在定义重叠。**
        -   **意图边界混淆分析**：这是对聚类审计的补充和深化。它会精确地列出每一个被判定为“边界模糊”的话语、它的原始意图、以及它最可能混淆的目标意图和对应的 p-value。**这份列表是您进行数据修正的最高优先级参考。**

-   **可视化图表 (位于 `outputs/figures/<运行时间>/`)**:
    -   **意图相似度热力图** (`intent_similarity_heatmap.png`)：一个矩阵图，颜色越亮表示两个意图的语义中心越接近。**可用于快速发现哪些意图对在语义上可能过于相似。**
    -   **全局话语散点图** (`global_scatterplot.png`)：所有话语在二维空间中的分布图。不同颜色代表不同的原始意图。图中用**黄边三角形**特殊标记出的点，就是被“意图边界混淆分析”识别出的高风险话语。**这使得您可以在宏观上快速定位意图重叠区域。**
    -   **意图内话语散点图** (`intent_*.png`)：每个意图一张图。图中标出了正常点（蓝色圆圈）和被判定的异常点（红色叉号），并附上了异常点的文本内容。**这是对审计报告中异常点列表的直观可视化，帮助您理解为何某个点被判定为异常。**

### 4.2. 数据增广 (`enrich` 命令)

运行 `enrich` 命令后，默认会在 `outputs/reports/` 目录下生成一份独立的、带时间戳的 Markdown 报告 (`enrichment_report_*.md`)。

-   **增广建议报告**：这份报告包含了为每个低样本意图生成的所有候选话语。**您应在人工审核这些话语后，再决定是否将它们加入您的原始数据集。** 如果您希望直接在控制台查看结果而不生成文件，可以使用 `--dry-run` 标志。
